apiVersion: 1

rulegroups:
  - name: 'Zookeeper Alerts'
    interval: '1m'
    rules:
      # Existing Grafana Alert
      - uid: 'zookeeper-session-expiry'
        title: 'Zookeeper Session Expiry Rate'
        condition: 'avg(rate(zookeeper_session_expiry_rate[5m])) > 5'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(rate(zookeeper_session_expiry_rate[5m]))'
            format: 'time_series'
        for: '5m'
        annotations:
          summary: 'High session expiry rate detected'
        labels:
          severity: 'critical'

      # Prometheus Alert: ZooKeeperDown
      - uid: 'zookeeper-down'
        title: 'ZooKeeper Instance Down'
        condition: 'avg(up{job="zookeeper"} == 0) > 0'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(up{job="zookeeper"} == 0)'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "ZooKeeper Instance Down"
          description: "The ZooKeeper instance on {{ $labels.instance }} is down."
        labels:
          severity: 'critical'

      # Prometheus Alert: HighCPUUsage
      - uid: 'high-cpu-usage'
        title: 'High CPU Usage on ZooKeeper'
        condition: 'avg(process_cpu_seconds_total{job="zookeeper"}) > 80'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(process_cpu_seconds_total{job="zookeeper"})'
            format: 'time_series'
        for: '2m'
        annotations:
          summary: "High CPU Usage on {{ $labels.instance }}"
          description: "CPU usage on {{ $labels.instance }} is above 80%."
        labels:
          severity: 'warning'

      # Prometheus Alert: MemoryUsageCritical
      - uid: 'memory-usage-critical'
        title: 'Critical Memory Usage on ZooKeeper'
        condition: 'avg(jvm_memory_heap_used_bytes / jvm_memory_heap_max_bytes{job="zookeeper"}) > 0.9'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(jvm_memory_heap_used_bytes / jvm_memory_heap_max_bytes{job="zookeeper"})'
            format: 'time_series'
        for: '2m'
        annotations:
          summary: "Critical Memory Usage on {{ $labels.instance }}"
          description: "Memory usage on {{ $labels.instance }} is above 90%."
        labels:
          severity: 'critical'

      # Prometheus Alert: JvmMemoryFillingUp
      - uid: 'jvm-memory-filling-up'
        title: 'JVM Memory Filling Up on ZooKeeper'
        condition: 'avg(jvm_memory_bytes_used / jvm_memory_bytes_max{area="heap", job="zookeeper"}) > 0.8'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(jvm_memory_bytes_used / jvm_memory_bytes_max{area="heap", job="zookeeper"})'
            format: 'time_series'
        for: '5m'
        annotations:
          summary: "JVM Memory Filling Up (Instance {{ $labels.instance }})"
          description: "JVM memory on {{ $labels.instance }} is filling up (> 80%). Labels: {{ $labels }} Value: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: CreateTooManyZnodes
      - uid: 'create-too-many-znodes'
        title: 'Too Many Znodes on ZooKeeper'
        condition: 'avg(znode_count{job="zookeeper"}) > 1000000'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(znode_count{job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Creating Too Many Znodes"
          description: "Instance {{ $labels.instance }} of job {{ $labels.job }} is creating too many znodes: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: CreateTooManyConnections
      - uid: 'create-too-many-connections'
        title: 'Too Many Connections on ZooKeeper'
        condition: 'avg(num_alive_connections{job="zookeeper"}) > 50'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(num_alive_connections{job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Creating Too Many Connections"
          description: "Instance {{ $labels.instance }} of job {{ $labels.job }} is creating too many connections: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: ZnodeTotalOccupiedMemoryTooBig
      - uid: 'znode-total-occupied-memory-too-big'
        title: 'Znode Total Occupied Memory Too Big on ZooKeeper'
        condition: 'avg(approximate_data_size / (1024 * 1024){job="zookeeper"}) > 1024'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(approximate_data_size / (1024 * 1024){job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Znode Total Occupied Memory Too Big"
          description: "Instance {{ $labels.instance }} of job {{ $labels.job }} has znode total occupied memory too big: {{ $value }} MB."
        labels:
          severity: 'warning'

      # Prometheus Alert: SetTooManyWatch
      - uid: 'set-too-many-watch'
        title: 'Too Many Watches on ZooKeeper'
        condition: 'avg(watch_count{job="zookeeper"}) > 10000'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(watch_count{job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Setting Too Many Watches"
          description: "Instance {{ $labels.instance }} of job {{ $labels.job }} is setting too many watches: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: LeaderElectionHappened
      - uid: 'leader-election-happened'
        title: 'Leader Election Happened on ZooKeeper'
        condition: 'increase(election_time_count{job="zookeeper"}[5m]) > 0'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'increase(election_time_count{job="zookeeper"}[5m])'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Leader Election Happened on Instance {{ $labels.instance }}"
          description: "Leader election has occurred on instance {{ $labels.instance }} of job {{ $labels.job }}: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: OpenTooManyFiles
      - uid: 'open-too-many-files'
        title: 'Too Many Open Files on ZooKeeper'
        condition: 'avg(open_file_descriptor_count{job="zookeeper"}) > 300'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(open_file_descriptor_count{job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Opening Too Many Files"
          description: "Instance {{ $labels.instance }} of job {{ $labels.job }} is opening too many files: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: FsyncTimeTooLong
      - uid: 'fsync-time-too-long'
        title: 'Fsync Time Too Long on ZooKeeper'
        condition: 'avg(rate(fsynctime_sum{job="zookeeper"}[1m])) > 100'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(rate(fsynctime_sum{job="zookeeper"}[1m]))'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Fsync Time Too Long"
          description: "Fsync time on instance {{ $labels.instance }} of job {{ $labels.job }} is too long: {{ $value }}."
        labels:
          severity: 'warning'

      # Prometheus Alert: TakeSnapshotTimeTooLong
      - uid: 'take-snapshot-time-too-long'
        title: 'Take Snapshot Time Too Long on ZooKeeper'
        condition: 'avg(rate(snapshottime_sum{job="zookeeper"}[5m])) > 100'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(rate(snapshottime_sum{job="zookeeper"}[5m]))'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Take Snapshot Time Too Long"
          description: "Snapshot time on instance {{ $labels.instance }} of job {{ $labels.job }} is too long: {{ $value }} ms."
        labels:
          severity: 'warning'

      # Prometheus Alert: AvgLatencyTooHigh
      - uid: 'avg-latency-too-high'
        title: 'Average Latency Too High on ZooKeeper'
        condition: 'avg(avg_latency{job="zookeeper"}) > 100'
        data:
          - datasourceUid: 'Prometheus'
            expr: 'avg(avg_latency{job="zookeeper"})'
            format: 'time_series'
        for: '1m'
        annotations:
          summary: "Instance {{ $labels.instance }} Average Latency Too High"
          description: "Average latency on instance {{ $labels.instance }} of job {{ $labels.job }} is too high: {{ $value }} ms."
        labels:
          severity: 'warning'
